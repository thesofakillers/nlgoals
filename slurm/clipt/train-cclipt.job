#!/bin/bash

#SBATCH --partition=gpu
#SBATCH --gres=gpu:1
#SBATCH --job-name=CCLIPT
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=18
#SBATCH --time=4:00:00
#SBATCH --mem-per-gpu=120G
#SBATCH --output=slurm/outputs/clipt_train_%A.out

source "./slurm/.secrets"

module purge
module load 2022
module load Anaconda3/2022.05

source activate nlgoals

srun python -u src/nlgoals/run/train-clipt.py \
  --data.data_dir /scratch-shared/gstarace/repos/thesis/data/calvin/task_D_D/ \
  --trainer.checkpoint.filename cclipt \
  --trainer.checkpoint.dirpath checkpoints/cclipt \
  --clipt.contextualize_text true \
  --clipt.precomputed_clip true
