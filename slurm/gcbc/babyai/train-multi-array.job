#!/bin/bash

#SBATCH --partition=gpu
#SBATCH --gres=gpu:1
#SBATCH --job-name=GCBC
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=18
#SBATCH --time=24:00:00
#SBATCH --mem-per-gpu=120G
#SBATCH --output=slurm/outputs/gcbc_b_train_%A_%a.out
#SBATCH --array=1-3%3

source "./slurm/.secrets"

data_path=/scratch-shared/gstarace/repos/thesis/data/babyai/cc/small

module purge
module load 2022
module load Anaconda3/2022.05

source activate nlgoals

# multiple seeds
HPARAMS_FILE="slurm/gcbc/babyai/train-multi-array.txt"

srun python src/nlgoals/run/babyai/train-gcbc.py \
  --config src/nlgoals/configs/babyai/train-gcbc.json \
  --clipt_checkpoint checkpoints/babyai/cclipt/last.ckpt \
  --clipt.precomputed_clip false \
  --clipt.contextualize_text true \
  --gcbc.rolling_traj false \
  --data.data_path=$data_path \
  --data.envs_size small \
  --trainer.logging.enable true \
  --trainer.checkpoint.dirpath "checkpoints/babyai/gcbc_cclipt/multi_task/" \
  --trainer.logging.enable true \
  --trainer.max_epochs 10 \
  $(head -$SLURM_ARRAY_TASK_ID $HPARAMS_FILE | tail -1)
