#!/bin/bash

#SBATCH --partition=gpu
#SBATCH --gres=gpu:1
#SBATCH --job-name=GCBC-MM
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=18
#SBATCH --time=24:00:00
#SBATCH --mem-per-gpu=120G
#SBATCH --output=slurm/outputs/gcbc_train_mm_%A.out

source "./slurm/.secrets"

data_path=/scratch-shared/gstarace/repos/thesis/data/babyai/cc/small

module purge
module load 2022
module load Anaconda3/2022.05

source activate nlgoals

srun python src/nlgoals/run/babyai/train-gcbc.py \
  --config src/nlgoals/configs/babyai/train-gcbc.json \
  --clipt_checkpoint checkpoints/babyai/clipt/clipt-s1.ckpt \
  --clipt.precomputed_clip false \
  --clipt.contextualize_text false \
  --gcbc.rolling_traj false \
  --data.data_path=$data_path \
  --data.envs_size small \
  --trainer.logging.enable true \
  --trainer.checkpoint.dirpath "checkpoints/babyai/gcbc_clipt_mm/multi_task/" \
  --trainer.logging.enable true \
  --gcbc.train_modality both \
  --gcbc.val_modality both \
  --seed 1
